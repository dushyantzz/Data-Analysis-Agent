{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install together pandas matplotlib seaborn plotly openpyxl python-docx PyPDF2 pillow numpy scikit-learn wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import docx\n",
    "import PyPDF2\n",
    "from PIL import Image\n",
    "import json\n",
    "import re\n",
    "from io import StringIO\n",
    "import together\n",
    "from together import Together\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOGETHER_API_KEY = \"cdd020e6a49733d3836952dbd379ccc3476264c76c0a510fcd9a6b490b588588\"\n",
    "MODEL_NAME = \"meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8\"\n",
    "client = Together(api_key=TOGETHER_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataAnalystAgent:\n",
    "    def __init__(self, api_key, model_name):\n",
    "        self.client = Together(api_key=api_key)\n",
    "        self.model_name = model_name\n",
    "        self.current_data = None\n",
    "        self.data_info = {}\n",
    "        self.conversation_history = []\n",
    "        \n",
    "    def query_llm(self, prompt, system_message=\"You are a senior data analyst with over 15 years of experience in advanced analytics, statistical modeling, and business intelligence across multiple industries. Your role is to thoroughly analyze the provided dataset, uncover meaningful patterns, trends, and anomalies, and generate actionable, descriptive insights that can drive strategic decision-making. For each insight, provide clear explanations, relevant statistical measures, and, where appropriate, suggest advanced data visualization techniques to communicate findings effectively to both technical and non-technical stakeholders. Anticipate potential business questions, highlight key opportunities or risks, and recommend next steps or further analyses. If any information or data context is missing, ask clarifying questions before proceeding. Present your findings in a structured, comprehensive, and business-oriented manner.\"):\n",
    "        try:\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=self.model_name,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": system_message},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                max_tokens=2048,\n",
    "                temperature=0.7\n",
    "            )\n",
    "            return response.choices[0].message.content\n",
    "        except Exception as e:\n",
    "            return f\"Error querying model: {str(e)}\"\n",
    "    \n",
    "    def read_file(self, file_path):\n",
    "        file_extension = os.path.splitext(file_path)[1].lower()\n",
    "        try:\n",
    "            if file_extension == '.csv':\n",
    "                return pd.read_csv(file_path)\n",
    "            elif file_extension in ['.xlsx', '.xls']:\n",
    "                return pd.read_excel(file_path)\n",
    "            elif file_extension == '.txt':\n",
    "                with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                    content = f.read()\n",
    "                return content\n",
    "            elif file_extension == '.docx':\n",
    "                doc = docx.Document(file_path)\n",
    "                content = '\\n'.join([paragraph.text for paragraph in doc.paragraphs])\n",
    "                return content\n",
    "            elif file_extension == '.pdf':\n",
    "                with open(file_path, 'rb') as f:\n",
    "                    reader = PyPDF2.PdfReader(f)\n",
    "                    content = ''\n",
    "                    for page in reader.pages:\n",
    "                        content += page.extract_text() + '\\n'\n",
    "                return content\n",
    "            elif file_extension in ['.jpg', '.jpeg', '.png', '.bmp', '.gif']:\n",
    "                img = Image.open(file_path)\n",
    "                return f\"Image loaded: {img.size} pixels, Mode: {img.mode}\"\n",
    "            else:\n",
    "                return f\"Unsupported file format: {file_extension}\"\n",
    "        except Exception as e:\n",
    "            return f\"Error reading file: {str(e)}\"\n",
    "    \n",
    "    def analyze_data(self, data, question=None):\n",
    "        if isinstance(data, pd.DataFrame):\n",
    "            summary = self.generate_data_summary(data)\n",
    "            if question:\n",
    "                prompt = f\"\"\"I have a dataset with the following summary:\n",
    "                {summary}\n",
    "                Dataset preview:\n",
    "                {data.head().to_string()}\n",
    "                Question: {question}\n",
    "                Please provide a detailed analysis and answer to this question based on the data.\"\"\"\n",
    "            else:\n",
    "                prompt = f\"\"\"I have a dataset with the following summary:\n",
    "                {summary}\n",
    "                Dataset preview:\n",
    "                {data.head().to_string()}\n",
    "                Please provide a comprehensive analysis of this dataset including:\n",
    "                1. Key insights and patterns\n",
    "                2. Data quality observations\n",
    "                3. Potential areas for further investigation\n",
    "                4. Suggested visualizations\"\"\"\n",
    "            system_message = \"\"\"You are an expert data analyst. Provide clear, actionable insights based on the data provided. Focus on practical findings and recommendations.\"\"\"\n",
    "            return self.query_llm(prompt, system_message)\n",
    "        elif isinstance(data, str):\n",
    "            if question:\n",
    "                prompt = f\"\"\"Text content: {data[:2000]}...\n",
    "                Question: {question}\n",
    "                Please analyze this text and answer the question.\"\"\"\n",
    "            else:\n",
    "                prompt = f\"\"\"Text content: {data[:2000]}...\n",
    "                Please provide a comprehensive analysis of this text including:\n",
    "                1. Key themes and topics\n",
    "                2. Summary of main points\n",
    "                3. Any patterns or insights\"\"\"\n",
    "            return self.query_llm(prompt)\n",
    "    \n",
    "    def generate_data_summary(self, df):\n",
    "        summary = f\"\"\"Dataset Shape: {df.shape[0]} rows, {df.shape[1]} columns\n",
    "        Columns and Data Types:\n",
    "        {df.dtypes.to_string()}\n",
    "        Missing Values:\n",
    "        {df.isnull().sum().to_string()}\n",
    "        Numerical Columns Summary:\n",
    "        {df.describe().to_string() if len(df.select_dtypes(include=[np.number]).columns) > 0 else 'No numerical columns'}\n",
    "        Categorical Columns:\n",
    "        {list(df.select_dtypes(include=['object']).columns)}\"\"\"\n",
    "        return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def create_visualizations(self, df):\n",
    "        if not isinstance(df, pd.DataFrame):\n",
    "            return\n",
    "        numerical_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "        if len(numerical_cols) > 0:\n",
    "            fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "            if len(numerical_cols) >= 1:\n",
    "                axes[0,0].hist(df[numerical_cols[0]].dropna(), bins=30, alpha=0.7)\n",
    "                axes[0,0].set_title(f'Distribution of {numerical_cols[0]}')\n",
    "            if len(numerical_cols) > 1:\n",
    "                corr_matrix = df[numerical_cols].corr()\n",
    "                sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0, ax=axes[0,1])\n",
    "                axes[0,1].set_title('Correlation Matrix')\n",
    "            missing_data = df.isnull().sum()\n",
    "            missing_data = missing_data[missing_data > 0]\n",
    "            if len(missing_data) > 0:\n",
    "                axes[1,0].bar(range(len(missing_data)), missing_data.values)\n",
    "                axes[1,0].set_xticks(range(len(missing_data)))\n",
    "                axes[1,0].set_xticklabels(missing_data.index, rotation=45)\n",
    "                axes[1,0].set_title('Missing Values')\n",
    "            type_counts = df.dtypes.value_counts()\n",
    "            axes[1,1].pie(type_counts.values, labels=type_counts.index, autopct='%1.1f%%')\n",
    "            axes[1,1].set_title('Data Types')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "    \n",
    "    def upload_and_analyze(self, file_path, question=None):\n",
    "        data = self.read_file(file_path)\n",
    "        if isinstance(data, str) and data.startswith('Error'):\n",
    "            return data\n",
    "        self.current_data = data\n",
    "        analysis = self.analyze_data(data, question)\n",
    "        if isinstance(data, pd.DataFrame):\n",
    "            self.create_visualizations(data)\n",
    "        return analysis\n",
    "    \n",
    "    def ask_followup(self, question):\n",
    "        if self.current_data is None:\n",
    "            return \"Please upload a file first\"\n",
    "        return self.analyze_data(self.current_data, question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = DataAnalystAgent(TOGETHER_API_KEY, MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "np.random.seed(42)\n",
    "n_records = 1000\n",
    "sample_data = {\n",
    "    'date': [datetime.now() - timedelta(days=x) for x in range(n_records)],\n",
    "    'product': np.random.choice(['Product A', 'Product B', 'Product C', 'Product D'], n_records),\n",
    "    'sales': np.random.normal(1000, 200, n_records),\n",
    "    'region': np.random.choice(['North', 'South', 'East', 'West'], n_records),\n",
    "    'customer_satisfaction': np.random.uniform(1, 5, n_records)\n",
    "}\n",
    "sample_df = pd.DataFrame(sample_data)\n",
    "sample_df['sales'] = sample_df['sales'].round(2)\n",
    "sample_df['customer_satisfaction'] = sample_df['customer_satisfaction'].round(1)\n",
    "sample_df.to_csv('sample_data.csv', index=False)\n",
    "print(sample_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = agent.upload_and_analyze('sample_data.csv')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "followup = agent.ask_followup(\"What are the key insights from this sales data?\")\n",
    "print(followup)"
   ]
  },

 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
